{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (1.5.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: sqlalchemy in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (1.4.47)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (from sqlalchemy) (2.0.2)\n",
      "Requirement already satisfied: openpyxl in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: chardet in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: xlrd in /Users/kolawole/opt/anaconda3/envs/notebook/lib/python3.10/site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install sqlalchemy\n",
    "!pip install openpyxl\n",
    "!pip install chardet\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 rows loaded into PostgreSQL database.\n",
      "1001 rows loaded into PostgreSQL database.\n",
      "1501 rows loaded into PostgreSQL database.\n",
      "2001 rows loaded into PostgreSQL database.\n",
      "2501 rows loaded into PostgreSQL database.\n",
      "3001 rows loaded into PostgreSQL database.\n",
      "3501 rows loaded into PostgreSQL database.\n",
      "4001 rows loaded into PostgreSQL database.\n",
      "4501 rows loaded into PostgreSQL database.\n",
      "5001 rows loaded into PostgreSQL database.\n",
      "5501 rows loaded into PostgreSQL database.\n",
      "6001 rows loaded into PostgreSQL database.\n",
      "Loading data from Excel file to PostgreSQL database complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Read column headers from Excel file\n",
    "header_df = pd.read_excel('/Users/kolawole/Documents/Femi_Report.xlsx', sheet_name='Sheet1 (2)', nrows=0)\n",
    "\n",
    "# Check for duplicate columns and rename them\n",
    "new_columns = []\n",
    "for col in header_df.columns:\n",
    "    new_col = col\n",
    "    suffix = 1\n",
    "    while new_col in new_columns:\n",
    "        new_col = col + \"_\" + str(suffix)\n",
    "        suffix += 1\n",
    "    new_columns.append(new_col)\n",
    "\n",
    "# Load Excel file into pandas dataframe in chunks\n",
    "chunksize = 500\n",
    "skiprows = 1\n",
    "while True:\n",
    "    \n",
    "    # Read chunk of data from Excel file\n",
    "    chunk = pd.read_excel('/Users/kolawole/Documents/Femi_Report.xlsx', sheet_name='Sheet1 (2)', skiprows=skiprows, nrows=chunksize, names=new_columns)\n",
    "    \n",
    "    # Check if chunk is empty, i.e., end of file reached\n",
    "    if chunk.empty:\n",
    "        break\n",
    "    \n",
    "    # Ignore the first row and rename the second row as \"id\"\n",
    "    chunk = chunk.iloc[1:].rename(columns={\"id\": \"id\"})\n",
    "    \n",
    "    # Connect to PostgreSQL database using SQLAlchemy\n",
    "    engine = create_engine('postgresql://postgres:Colymore0900@localhost:5432/analytics_db')\n",
    "    \n",
    "    # Insert data into PostgreSQL database\n",
    "    chunk.to_sql('rev_new', engine, if_exists='replace', index=False)\n",
    "    \n",
    "    # Close database connection\n",
    "    engine.dispose()\n",
    "    \n",
    "    # Update skiprows counter\n",
    "    skiprows += chunksize\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"{skiprows} rows loaded into PostgreSQL database.\")\n",
    "    \n",
    "print(\"Loading data from Excel file to PostgreSQL database complete.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE CSV FILE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String\n",
    "\n",
    "# Connect to database using SQLAlchemy engine\n",
    "engine = create_engine('postgresql://postgres:Colymore0900@localhost/analytics_db')\n",
    "conn = engine.connect()\n",
    "metadata = MetaData()\n",
    "\n",
    "# Open CSV file and read header row\n",
    "with open('/Users/kolawole/Documents/femicopy_2.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "\n",
    "    # Identify unique column names and handle duplicates\n",
    "    unique_header = []\n",
    "    for col in header:\n",
    "        if col not in unique_header:\n",
    "            unique_header.append(col)\n",
    "        else:\n",
    "            i = 2\n",
    "            while f\"{col}_{i}\" in unique_header:\n",
    "                i += 1\n",
    "            unique_header.append(f\"{col}_{i}\")\n",
    "\n",
    "    # Create table with identified column names\n",
    "    table = Table('mytable', metadata, *[Column(name, String) for name in unique_header])\n",
    "    table.create(conn)\n",
    "\n",
    "    # Load data into table\n",
    "    for row in reader:\n",
    "        row_dict = {name: value for name, value in zip(unique_header, row)}\n",
    "        ins = table.insert().values(**row_dict)\n",
    "        conn.execute(ins)\n",
    "\n",
    "# Close database connection\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
