{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install snowflake-sqlalchemy\n",
    "!pip install sqlalchemy\n",
    "!pip install tqdm\n",
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /Users/kolawole/Documents/mendeley_json/mendeley_json/nbagames.json: 31686lines [00:00, 112657.70lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/kolawole/Documents/mendeley_json/mendeley_json/nbagames.json uploaded to stage data_lake.nba_games_stage\n",
      "Table nba_games created\n",
      "Data loaded to analytics_dbt.data_lake.nba_games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /Users/kolawole/Documents/mendeley_json/mendeley_json/dblp.json: 1984049lines [00:01, 1241671.30lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/kolawole/Documents/mendeley_json/mendeley_json/dblp.json uploaded to stage data_lake.dblp_data_stage\n",
      "Table dblp_data created\n",
      "Data loaded to analytics_dbt.data_lake.dblp_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /Users/kolawole/Documents/mendeley_json/mendeley_json/twitter.twitter2.json: 1984049lines [00:12, 164740.26lines/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /Users/kolawole/Documents/mendeley_json/mendeley_json/twitter.twitter2.json uploaded to stage data_lake.twitter_data_stage\n",
      "Table twitter_data created\n",
      "Data loaded to analytics_dbt.data_lake.twitter_data\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Connect to Snowflake account\n",
    "conn = snowflake.connector.connect(\n",
    "    user='',\n",
    "    password='',\n",
    "    account='.canada-central.azure',\n",
    ")\n",
    "\n",
    "# Define database and schema\n",
    "database = 'analytics_dbt'\n",
    "schema = 'data_lake'\n",
    "\n",
    "# Set current database\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(f\"USE DATABASE {database}\")\n",
    "\n",
    "# List of files to load, and dictionary of corresponding table names\n",
    "file_dict = {\n",
    "    '/Users/kolawole/Documents/mendeley_json/mendeley_json/nbagames.json': 'nba_games',\n",
    "    '/Users/kolawole/Documents/mendeley_json/mendeley_json/dblp.json': 'dblp_data',\n",
    "    '/Users/kolawole/Documents/mendeley_json/mendeley_json/twitter.twitter2.json': 'twitter_data'\n",
    "}\n",
    "\n",
    "# Loop over files\n",
    "for file_path, table_name in file_dict.items():\n",
    "    # Load data from file\n",
    "    json_dumps = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for lines in tqdm(f, desc=f\"Loading {file_path}\", unit=\"lines\"):\n",
    "            json_dumps.append(lines)\n",
    "    f.close()\n",
    "    data = pd.DataFrame({'data': json_dumps})\n",
    "\n",
    "    # Create stage for file\n",
    "    create_stage_query = f\"CREATE OR REPLACE STAGE {schema}.{table_name}_stage\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(create_stage_query)\n",
    "\n",
    "    # Put file into stage\n",
    "    put_file_query = f\"PUT file://{file_path} @{schema}.{table_name}_stage\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(put_file_query)\n",
    "        print(f\"File {file_path} uploaded to stage {schema}.{table_name}_stage\")\n",
    "\n",
    "    # Load data into Snowflake\n",
    "    with conn.cursor() as cur:\n",
    "        # Create table if it doesn't exist\n",
    "        create_table_query = f\"CREATE TABLE IF NOT EXISTS {database}.{schema}.{table_name} (data VARIANT)\"\n",
    "        cur.execute(create_table_query)\n",
    "        print(f\"Table {table_name} created\")\n",
    "\n",
    "        # Load data into table\n",
    "        copy_query = f\"COPY INTO {database}.{schema}.{table_name} FROM @{schema}.{table_name}_stage FILE_FORMAT = (TYPE = 'JSON')\"\n",
    "        cur.execute(copy_query)\n",
    "        print(f\"Data loaded to {database}.{schema}.{table_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fe07ec4ea739fc0b552c3c1c3ac8fe1e5151ffb3bf191e28a3fecff8013090b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
